---
title: "Reproducible Research â€“ Course Project 2"
author: "David Levy"
date: "11/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis

This analysis makes use of the NOAA storm Database and attempts to answer some basic questions about severe weather events. More specifically, we are seeking answers to the following questions

1. *Across the United States, which types of events (as indicated in the \color{red}{\verb|EVTYPE|}`EVTYPE` variable) are most harmful with respect to population health?*

2. *Across the United States, which types of events have the greatest economic consequences?*



Title: Your document should have a title that briefly summarizes your data analysis
Synopsis: Immediately after the title, there should be a synopsis which describes and summarizes your analysis in at most 10 complete sentences.


## Data Processing

#### R Packages Used for Analysis

```{r Calling analysis libraries}

library(tidyverse)
library(ggplot2)

```

#### Unzipping and Reading Data

We begin data processing by unzipping and reading the compressed Storm Data data file into memory:

```{r Unzipping and reading data, cache=TRUE}

# store data file name
dataFile  <- 'repdata_data_StormData.csv.bz2'

# download the file if it doesn't exist already
if(!file.exists(dataFile)) {
    download.file('https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2',
                  destfile = dataFile, method = 'curl')
}

# initiate a connection to the data file
bzConnection <- bzfile(dataFile)

# initiate tibble with file contents
stormData <- read.csv(bzConnection)

```

In order to better understand the data set as it has been provided, we can visualize the top and bottom of our new tibble and get a printout of the structure of the data:

```{r Inspecting the data frame}

# visualize the top of the tibble
head(stormData)

# visualize the bottom of the tibble
tail(stormData)

# summarize the structure of the tibble
str(stormData)

```

#### Data Processing and Transformations

Based on what we observed in the previous section, this data set is bit unwieldy in terms of its width, meaning that we likely have more variables than we need in order to answer the two questions emphasized in the **Synopsis** section. Recall that of particular interest are the `EVTYPE` and its relationship with indicators of (1) population health and (2) economic consequences. Below is a summary of how each variable has been treated in this analysis and a brief rationale for each respective decision:

- `STATE__`   : We will drop this variable. It is redundant and we do not need a numerical representation of the state of storm events for the present analysis.
- `BGN_DATE`  : We will drop this variable. There are no questions pertaining to the temporal aspects of the storm events recorded in this data set.
- `BGN_TIME`  : We will drop this variable. There are no questions pertaining to the temporal aspects of the storm events recorded in this data set.
- `TIME_ZONE` : We will drop this variable. There are no questions pertaining to the temporal aspects of the storm events recorded in this data set.
- `COUNTY`    : 
- `COUNTYNAME`: 
- `STATE`     : We will retain this variable for our analysis. A within-state comparison may be germane to questions of economic impact.
- `EVTYPE`    : We will retain this variable for our analysis. This variable is central to the questions at hand, as both are asked within the framework of of event type.
- `BGN_RANGE` : 
- `BGN_AZI`   : 
- `BGN_LOCATI`: 
- `END_DATE`  : We will drop this variable. There are no questions pertaining to the temporal aspects of the storm events recorded in this data set.
- `END_TIME`  : We will drop this variable. There are no questions pertaining to the temporal aspects of the storm events recorded in this data set.
- `COUNTY_END`: 
- `COUNTYENDN`: 
- `END_RANGE` : 
- `END_AZI`   : 
- `END_LOCATI`: 
- `LENGTH`    : 
- `WIDTH`     : 
- `F`         : 
- `MAG`       : 
- `FATALITIES`: 
- `INJURIES`  : 
- `PROPDMG`   : 
- `PROPDMGEXP`: 
- `CROPDMG`   : 
- `CROPDMGEXP`: 
- `WFO`       : 
- `STATEOFFIC`: 
- `ZONENAMES` : 
- `LATITUDE`  : 
- `LONGITUDE` : We 
- `LATITUDE_E`: 
- `LONGITUDE_`: 
- `REMARKS`   : 
- `REFNUM`    : 

Now that we have summarized how we intend to use (or not use) each variable in the data set, we can transform data appropriately:

```{Data processing and transformations}
```


## Results

There should be a section titled Results in which your results are presented.
You may have other sections in your analysis, but Data Processing and Results are required.
The analysis document must have at least one figure containing a plot.
Your analysis must have no more than three figures. Figures may have multiple plots in them (i.e. panel plots), but there cannot be more than three figures total.
You must show all your code for the work in your analysis document. This may make the document a bit verbose, but that is okay. In general, you should ensure that \color{red}{\verb|echo = TRUE|}echo = TRUE for every code chunk (this is the default setting in knitr).
